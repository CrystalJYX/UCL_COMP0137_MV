{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import io\n",
    "from scipy.io import loadmat\n",
    "import cv2 as cv \n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import os # for reading all files in a folder\n",
    "#pylab.rcParams['figure.figsize'] = (12.0, 10.0)\n",
    "\n",
    "# plots are too big to save, this file cannot be reopened, \n",
    "# so I changed the size of plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part H: Tracking and Homographies\n",
    "\n",
    "In this part we use Practical 9c to track the positions of the four corners of the square and project a cube into the images. \n",
    "\n",
    "TO DO: QUESTIONS TO THINK ABOUT...\n",
    "\n",
    "- Do the results look realistic? \n",
    "- If not then what factors do you think might be causing this\n",
    "\n",
    "\n",
    "TO DO: your routines for computing a homography and extracting a valid rotation and translation go in the code below. Tips:\n",
    "- you may define functions for T and H matrices respectively.\n",
    "- you may need to turn the points into homogeneous form before any other computation. \n",
    "- you may need to solve a linear system in Ah = 0 form. Write your own routines or using the builtin function 'svd'. \n",
    "- you may apply the direct linear transform (DLT) algorithm to recover the best homography H.\n",
    "- you may explain what & why you did in the report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Copy and paste the function HW2_Practical9c in here. \n",
    "\n",
    "#Likelihood function is simple patch similarity\n",
    "\n",
    "def computeLikelihood(image, template):\n",
    "    #opencv's available methods - experiment with these\n",
    "    #careful what range the output is!\n",
    "    methods = [cv.TM_CCOEFF, cv.TM_CCOEFF_NORMED, cv.TM_CCORR,\n",
    "            cv.TM_CCORR_NORMED, cv.TM_SQDIFF, cv.TM_SQDIFF_NORMED]\n",
    "    \n",
    "    likelihood = cv.matchTemplate(image[:,:,2], template, methods[0])\n",
    "    # (You can also try converting the image to greyscale instead of using the third channel as above with \n",
    "    # cv.cvtColor(image, cv.COLOR_BGR2GRAY))\n",
    "    \n",
    "    #we can pad to make this the size of the input image (for easier indexing)   \n",
    "    pad_first = int(template.shape[0])\n",
    "    pad_second = int(template.shape[1])\n",
    "    pad_amounts = ((0, pad_first-1), (0, pad_second-1))\n",
    "    likelihood = np.pad(likelihood, pad_amounts, 'constant')\n",
    "    likelihood[likelihood<0] = 0 # to avoid negative weights \n",
    "    \n",
    "    # apply a 10x10 averaging filter for stability. You can experiment with different sizes. \n",
    "    kernel = np.ones((10,10),np.float32)/100\n",
    "    smoothed = cv.filter2D(likelihood,-1,kernel) \n",
    "    return smoothed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HW2_Practical9c(corner):\n",
    "    template = sp.io.loadmat(corner+'.mat')['pixelsTemplate']\n",
    "    #let's show the template\n",
    "    print('We are matching this template with shape: ', template.shape)\n",
    "    plt.imshow(template)\n",
    "    plt.show()\n",
    "\n",
    "    # Load all images in folder\n",
    "    images = []\n",
    "    iFrame = 0\n",
    "    folder = 'Pattern01/'\n",
    "    lst = os.listdir(folder)\n",
    "    lst.sort()\n",
    "\n",
    "    for frameNum in lst:\n",
    "        images.append(cv.imread(folder+frameNum))\n",
    "        iFrame += 1\n",
    "    # plot first image \n",
    "    plt.imshow(images[0])\n",
    "    plt.show()\n",
    "\n",
    "    imgHeight, imgWidth, colors = images[0].shape\n",
    "    numParticles = 2000;\n",
    "    weight_of_samples = np.ones((numParticles,1))\n",
    "\n",
    "    # TO DO: normalize the weights (may be trivial this time) [done]\n",
    "    #weight_of_samples = weight_of_samples #replace this \n",
    "    weight_of_samples = weight_of_samples/np.sum(weight_of_samples)\n",
    "\n",
    "\n",
    "    # Initialize which samples from \"last time\" we want to propagate: all of\n",
    "    # them!:\n",
    "    samples_to_propagate = range(0, numParticles)\n",
    "\n",
    "\n",
    "    # ============================\n",
    "    # NOT A TO DO: You don't need to change the code below, but eventually you may\n",
    "    # want to vary the number of Dims (compare for example to lab 9b) \n",
    "    numDims_w = 2;\n",
    "    # Here we randomly initialize some particles throughout the space of w:\n",
    "    particles_old = np.random.rand(numParticles, numDims_w)\n",
    "    particles_old[:,0] = particles_old[:,0] * imgHeight\n",
    "    particles_old[:,1] = particles_old[:,1] * imgWidth\n",
    "    # ============================\n",
    "\n",
    "    #Initialize a temporary array r to store the per-frame MAP estimate of w. This is what we'll return in the end.\n",
    "    r = np.zeros((iFrame, numDims_w));\n",
    "\n",
    "    for iTime in range(iFrame):\n",
    "        print('Processing Frame', iTime)\n",
    "        # TO DO: compute the cumulative sume of the weights. [done]\n",
    "        #cum_hist_of_weights = np.linspace(0, 1, numParticles) # replace this\n",
    "        #print(weight_of_samples)\n",
    "        cum_hist_of_weights = np.cumsum(weight_of_samples)\n",
    "        \n",
    "\n",
    "        # ==============================================================\n",
    "        # Resample the old distribution at time t-1, and select samples, favoring\n",
    "        # those that had a higher posterior probability.\n",
    "        # ==============================================================\n",
    "        samples_to_propagate = np.zeros(numParticles, dtype=np.int32)\n",
    "\n",
    "        # Pick random thresholds in the cumulative probability's range [0,1]:\n",
    "        some_threshes = np.random.rand(numParticles)\n",
    "\n",
    "\n",
    "        # For each random threshold, find which sample in the ordered set is\n",
    "        # the first one to push the cumulative probability above that\n",
    "        # threshold, e.g. if the cumulative histogram goes from 0.23 to 0.26\n",
    "        # between the 17th and 18th samples in the old distribution, and the\n",
    "        # threshold is 0.234, then we'll want to propagate the 18th sample's w\n",
    "        # (i.e. particle #18).\n",
    "\n",
    "        for sampNum in range(numParticles): \n",
    "            thresh = some_threshes[sampNum]\n",
    "            for index in range (numParticles):\n",
    "                if cum_hist_of_weights[index] > thresh:\n",
    "                    break\n",
    "            samples_to_propagate[sampNum] = index\n",
    "\n",
    "        # Note: it's ok if some of the old particles get picked repeatedly, while\n",
    "        # others don't get picked at all.\n",
    "\n",
    "\n",
    "        # =================================================\n",
    "        # Visualize if you want\n",
    "        # =================================================\n",
    "        #plt.title('Cumulative histogram of probabilities for sorted list of particles')\n",
    "        #plt.plot(np.zeros(numParticles), some_threshes,'b.')\n",
    "        #plt.plot(range(0, numParticles), cum_hist_of_weights, 'rx-')\n",
    "        #which_sample_ids = np.unique(samples_to_propagate)\n",
    "        #how_many_of_each = np.bincount(np.ravel(samples_to_propagate))\n",
    "        #for k in range(len(which_sample_ids)):\n",
    "        #    plt.plot(which_sample_ids[k], 0, 'bo-', markersize = 3 * how_many_of_each[k], markerfacecolor='white')\n",
    "        #plt.xlabel('Indeces of all available samples, with larger blue circles for frequently re-sampled particles\\n(Iteration %01d)' % iTime)\n",
    "        #plt.ylabel('Cumulative probability');\n",
    "        #plt.show()\n",
    "        # =================================================\n",
    "        # =================================================\n",
    "\n",
    "        # Predict where the particles we sampled from the old distribution of \n",
    "        # state-space will go in the next time-step. This means we have to apply \n",
    "        # the motion model to each old sample.\n",
    "        particles_new = np.zeros_like(particles_old)\n",
    "        for particleNum in range(numParticles):\n",
    "            # TO DO: Incorporate some noise, e.g. Gaussian noise with std 20,\n",
    "            # into the current location (particles_old), to give a Brownian\n",
    "            # motion model.\n",
    "            #particles_new[particleNum, :] =  particles_old[particleNum, :] # replace this \n",
    "            noise = np.random.normal(0,20,2)\n",
    "            particles_new[particleNum, :] =  particles_old[samples_to_propagate[particleNum], :] + noise\n",
    "\n",
    "            \n",
    "        # TO DO: Not initially, but change the motion model above to have\n",
    "        # different degrees of freedom, and optionally completely different\n",
    "        # motion models. See Extra Credit for more instructions.\n",
    "\n",
    "        #calculate likelihood function\n",
    "        likelihood = computeLikelihood(images[iTime], template)\n",
    "\n",
    "        #plot results\n",
    "        f, axarr = plt.subplots(1, 2)\n",
    "        axarr[0].imshow(images[iTime])\n",
    "        axarr[0].set_title('Particles')\n",
    "        # now draw the particles onto the image\n",
    "        axarr[0].plot(particles_new[:,1]+template.shape[1]/2, particles_new[:,0]+template.shape[0]/2, 'rx')\n",
    "\n",
    "        #plot the likelihood\n",
    "        axarr[1].imshow(likelihood)\n",
    "        axarr[1].set_title('Likelihood')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # From here we incorporate the data for the new state (time t):\n",
    "        # The new particles accompanying predicted locations in state-space\n",
    "        # for time t, are missing their weights: how well does each particle\n",
    "        # explain the observations x_t?\n",
    "        for particleNum in range(numParticles):\n",
    "\n",
    "            # Convert the particle from state-space w to measurement-space x:\n",
    "            # Note: that step is trivial here since both are in 2D space of image\n",
    "            # coordinates\n",
    "\n",
    "            # Within the loop, we evaluate the likelihood of each particle:\n",
    "            particle = particles_new[particleNum, :]\n",
    "            # Check that the predicted location is a place we can really evaluate\n",
    "            # the likelihood.\n",
    "            inFrame = particle[0] >= 0.0 and  particle[0] <= imgHeight and particle[1] >= 0.0 and particle[1] <= imgWidth\n",
    "            if inFrame:\n",
    "                minX = particle[1]\n",
    "                minY = particle[0]\n",
    "\n",
    "                weight_of_samples[particleNum] = likelihood[int(minY), int(minX)]\n",
    "\n",
    "            else:\n",
    "                weight_of_samples[particleNum] = 0.0\n",
    "\n",
    "        # TO DO: normalize the weights [done]\n",
    "        #weight_of_samples = weight_of_samples # replace this\n",
    "        weight_of_samples = weight_of_samples/np.sum(weight_of_samples)\n",
    "\n",
    "        # find the location of the particle with highest weight\n",
    "        indices = np.argsort(weight_of_samples,0)\n",
    "        bestScoringParticles = particles_new[np.squeeze(indices[-15:]), :]\n",
    "        plt.plot(bestScoringParticles[-1:,1], bestScoringParticles[-1:,0], 'rx')\n",
    "        # Return the MAP of middle position. Add template.shape/2 because matchTemplate finds the position of the upper left corner \n",
    "        # of the template. We want to plot the centre of the template. \n",
    "        r[iTime,:] = bestScoringParticles[-1,1]+template.shape[1]/2,bestScoringParticles[-1,0]+template.shape[0]/2\n",
    "        print(r[iTime,:])   \n",
    "        plt.show()\n",
    "\n",
    "        #print the original image and the position of the tracked corner.\n",
    "        plt.imshow(images[iTime])\n",
    "        plt.plot(r[iTime,0],r[iTime,1],'rx')\n",
    "        plt.show()\n",
    "        # Now we're done updating the state for time t. \n",
    "        # For Condensation, just clean up and prepare for the next round of \n",
    "        # predictions and measurements:\n",
    "        particles_old = particles_new\n",
    "\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of running the code here, you can also save the output of each function in a numpy array in HW2_Practical9c \n",
    "# and load it here. This could be handy if you need different hyperparameters for each corner.\n",
    "# change to smaller size of plots\n",
    "pylab.rcParams['figure.figsize'] = (3, 2.5) \n",
    "LLs = HW2_Practical9c( 'll' )\n",
    "LRs = HW2_Practical9c( 'lr' )\n",
    "ULs = HW2_Practical9c( 'ul' )\n",
    "URs = HW2_Practical9c( 'ur' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remark: \n",
    "The plots above show an estimated track (2D locations over time) of one of the corners of the pattern moved. The particle randonly distribute in the first picture and then they move to the area which has high posterior. And finally, all the points concentrate on the each corner. (same as HW2_Practical9c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all images in folder\n",
    "images = []\n",
    "nFrame = 0\n",
    "folder = 'Pattern01/'\n",
    "lst = os.listdir(folder)\n",
    "lst.sort()\n",
    "\n",
    "for frameNum in lst:\n",
    "    images.append(cv.imread(folder+frameNum))\n",
    "    nFrame += 1\n",
    "# plot first image \n",
    "plt.imshow(images[0])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Coordinates of the known target object (a dark square on a plane) in 3D:\n",
    "XCart = np.array([[-50, -50,  50,  50],\n",
    "          [50, -50, -50,  50],\n",
    "            [0, 0, 0, 0]])\n",
    "\n",
    "# These are some approximate intrinsics for this footage.\n",
    "K = np.array([[640, 0, 320],\n",
    "          [0, 512, 256],\n",
    "            [0, 0, 1]])\n",
    "\n",
    "# Define 3D points of wireframe object.\n",
    "XWireFrameCart = np.array([[-50, -50,  50,  50, -50, -50,  50,  50],\n",
    "          [50, -50, -50,  50, 50, -50, -50,  50],\n",
    "            [0, 0, 0, 0, -100, -100, -100, -100, ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projectiveCamera(K,T,XCart):\n",
    "    ##TODO\n",
    "    # The goal of this function is to project points in XCart through projective camera\n",
    "    # defined by intrinsic matrix K and extrinsic matrix T. In essence, this function takes a set of points \n",
    "    # in 3D world space, XCart, and projects them into camera image space by applying the extrinsic matrix T \n",
    "    # and then applying the intrinsic matrix K.\n",
    "    # \n",
    "    # There are three steps.\n",
    "    # 1) Move from world space to camera space. \n",
    "    #            camera space points = extrinsics T * world space points \n",
    "    #\n",
    "    # 2) Applying the intrinsics matrix to the camera space points after normalizing\n",
    "    #           homogeneous image space points = K * normalized camera space points\n",
    "    # \n",
    "    # 3) Move to image space cartesian points from image space homogeneous points, involves a \n",
    "    # normalization using the third row.\n",
    "    \n",
    "    \n",
    "    # TO DO: Replace this\n",
    "    #XImCart = []\n",
    "\n",
    "    # TO DO: Convert Cartesian 3d points XCart to homogeneous coordinates XHom\n",
    "    #XHom = np.vstack([XCart,np.ones(XCart.shape[1])])\n",
    "    XHom = np.concatenate((XCart, np.ones((1,XCart.shape[1]))), axis=0)\n",
    "    # TO DO: Apply extrinsic matrix to XHom, to move to frame of reference of camera\n",
    "    XHomCam = T @ XHom\n",
    "    \n",
    "    # TO DO: Project points into normalized camera coordinates xCamHom (remove 4th row)\n",
    "    xCamHom = np.delete(XHomCam, 3, 0)\n",
    "    \n",
    "    # TO DO: Move points to image coordinates xImHom by applying intrinsic matrix\n",
    "    XImHom = K @ xCamHom\n",
    "    \n",
    "    # TO DO: Convert points back to Cartesian coordinates xImCart\n",
    "    XImCart = XImHom[0:2,:]/XImHom[2,:]\n",
    "    \n",
    "    return XImCart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solveAXEqualsZero(A):\n",
    "    # TO DO: Write this routine - it should solve Ah = 0. You can do this using SVD. Consult your notes! \n",
    "    # Hint: SVD will be involved. \n",
    "    U,L,V = np.linalg.svd(A)\n",
    "    V_t = V.T\n",
    "    h = V_t[:,-1] # last column of V\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcBestHomography(pts1Cart, pts2Cart):\n",
    "    \n",
    "    # This function should apply the direct linear transform (DLT) algorithm to calculate the best \n",
    "    # homography that maps the cartesian points in pts1Cart to their corresonding matching cartesian poitns \n",
    "    # in pts2Cart.\n",
    "    \n",
    "    # This function calls solveAXEqualsZero. Make sure you are wary of how to reshape h into a 3 by 3 matrix. \n",
    "\n",
    "    n_points = pts1Cart.shape[1]\n",
    "    \n",
    "    # TO DO: replace this:\n",
    "    H = np.identity(3)\n",
    "\n",
    "    # TO DO: \n",
    "    # First convert points into homogeneous representation\n",
    "    # Hint: we've done this before  in the skeleton code we provide.\n",
    "    pts1Hom = np.concatenate((pts1Cart, np.ones((1,pts1Cart.shape[1]))), axis=0)\n",
    "    pts2Hom = np.concatenate((pts2Cart, np.ones((1,pts2Cart.shape[1]))), axis=0)\n",
    "    \n",
    "    # Then construct the matrix A, size (n_points * 2, 9)\n",
    "    # Consult the notes!\n",
    "    A = np.ones((n_points * 2, 9))\n",
    "    for i in range(n_points):\n",
    "            u = pts1Cart[0,i] # ui\n",
    "            v = pts1Cart[1,i] # vi\n",
    "            x = pts2Cart[0,i] # xi\n",
    "            y = pts2Cart[1,i] # yi\n",
    "            A[2*i,:]= [0,0,0,-u,-v,-1,y*u,y*v,y]       \n",
    "            A[2*i+1,:]= [u,v,1,0,0,0,-x*u,-x*v,-x]\n",
    "        \n",
    "    # Solve Ah = 0 using solveAXEqualsZero and get h.\n",
    "    h = solveAXEqualsZero(A)\n",
    "    # Reshape h into the matrix H, values of h go first into rows of H\n",
    "    H = np.reshape(h,H.shape)\n",
    "\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the next cell first for context!\n",
    "\n",
    "def estimatePlanePose(XImCart,XCart,K):\n",
    "    # The goal of this function is to estimate the pose of a plane relative to camera (extrinsic matrix)\n",
    "    # given points in image space xImCart, points in 3D world space XCart, and an intrinsics matrix K.\n",
    "    \n",
    "    # TO DO: replace this\n",
    "    # T = []\n",
    "\n",
    "    # TO DO: Convert Cartesian image points XImCart to homogeneous representation XImHom\n",
    "    XImHom = np.concatenate((XImCart, np.ones((1,XImCart.shape[1]))), axis=0)\n",
    "    \n",
    "    # TO DO: Convert image co-ordinates XImHom to normalized camera coordinates XCamHom    \n",
    "    XCamHom = np.linalg.inv(K) @ XImHom\n",
    "    \n",
    "    # TO DO: Estimate homography H mapping homogeneous (x,y) coordinates of positions\n",
    "    # in real world to XCamHom (convert XCamHom to Cartesian, calculate the homography) -\n",
    "    # use the routine you wrote for Practical 1B\n",
    "    XCamHom = XCamHom[0:2] / XCamHom[2]\n",
    "    #XCamCart = XCamHom[0:2,:] / np.tile([XCamHom[2,:]],(2,1))\n",
    "    XCart = np.delete(XCart, 2, 0)\n",
    "    H = calcBestHomography(XCart,XCamHom)\n",
    "          \n",
    "        \n",
    "    # TO DO: Estimate first two columns of rotation matrix R from the first two\n",
    "    # columns of H using the SVD. NOTE: You do not need to transpose v from linalg.svd    \n",
    "    U,L,V_T = np.linalg.svd(H[:,0:2]) \n",
    "    rota = np.array([[1,0],[0,1],[0,0]])\n",
    "    R = np.zeros((3,3))\n",
    "    R[:,:2] = U@rota@V_T # first two columns \n",
    "    \n",
    "    \n",
    "    # TO DO: Estimate the third column of the rotation matrix by taking the cross\n",
    "    # product of the first two columns\n",
    "    R[:,2] = np.cross(R[:,0],R[:,1]) # the third column\n",
    "\n",
    "        \n",
    "    # TO DO: Check that the determinant of the rotation matrix is positive - if\n",
    "    # not then multiply last column by -1.\n",
    "    if np.linalg.det(R) <= 0:\n",
    "        R[:,2] = -R[:,2]   \n",
    "    \n",
    "    # TO DO: Estimate the translation t by finding the appropriate scaling factor k\n",
    "    # and applying it to the third colulmn of H\n",
    "    k = np.sum(H[:,:2]/R[:,:2])/6 \n",
    "    t = H[:,2].reshape((3,1))/k\n",
    "    \n",
    "    # TO DO: Check whether t_z is negative - if it is then multiply t by -1 and\n",
    "    # the first two columns of R by -1.\n",
    "    if t[2] < 0:\n",
    "        t = -t\n",
    "        R[:,:2] = -R[:,:2]     \n",
    "            \n",
    "    # TO DO: Assemble transformation into matrix form\n",
    "    T = np.hstack((R,t))\n",
    "    T = np.vstack((T, np.array([0,0,0,1])))\n",
    "                  \n",
    "    return T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iFrame in range(nFrame):\n",
    "    #xImCart = np.array([LLs[iFrame,:].T, ULs[iFrame,:].T, URs[iFrame,:].T, LRs[iFrame,:].T]).T\n",
    "\n",
    "    # since this file is too big if containing many large plots\n",
    "    # I choose to output the plot every 5 iFrame\n",
    "    if iFrame%5 == 0:\n",
    "        xImCart = np.array([LLs[iFrame,:].T, ULs[iFrame,:].T, URs[iFrame,:].T, LRs[iFrame,:].T]).T\n",
    "\n",
    "        # get a frame from footage \n",
    "        im = images[iFrame]\n",
    "\n",
    "        # Draw image and 2d points\n",
    "        plt.imshow(im)\n",
    "        plt.scatter(x = xImCart[0,:], y = xImCart[1,:],c = 'r')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        #TO DO: Use your routine to calculate TEst the extrinsic matrix relating the\n",
    "        #plane position to the camera position.\n",
    "        T = estimatePlanePose(xImCart, XCart, K)\n",
    "        XWireFrameCartProjected = projectiveCamera(K,T,XWireFrameCart)\n",
    "    \n",
    "        # TO DO: Draw a wire frame cube using data XWireFrameCart. You need to\n",
    "        # 1) project the vertices of a 3D cube through the projective camera;\n",
    "        # 2) draw lines betweeen the resulting 2d image points.\n",
    "        # Note: CONDUCT YOUR CODE FOR DRAWING XWireFrameCart HERE\n",
    "        plt.imshow(im)\n",
    "        plt.plot(xImCart[0,],xImCart[1,],'r.')\n",
    "        plt.plot(XWireFrameCartProjected[0,],XWireFrameCartProjected[1,],'g.')\n",
    "\n",
    "        # side\n",
    "        plt.plot([XWireFrameCartProjected[0,0], XWireFrameCartProjected[0,4]], [XWireFrameCartProjected[1,0], XWireFrameCartProjected[1,4]],'g-')\n",
    "        plt.plot([XWireFrameCartProjected[0,1], XWireFrameCartProjected[0,5]], [XWireFrameCartProjected[1,1], XWireFrameCartProjected[1,5]],'g-')\n",
    "        plt.plot([XWireFrameCartProjected[0,2], XWireFrameCartProjected[0,6]], [XWireFrameCartProjected[1,2], XWireFrameCartProjected[1,6]],'g-')\n",
    "        plt.plot([XWireFrameCartProjected[0,3], XWireFrameCartProjected[0,7]], [XWireFrameCartProjected[1,3], XWireFrameCartProjected[1,7]],'g-')\n",
    "\n",
    "        # bottom\n",
    "        plt.plot([XWireFrameCartProjected[0,0], XWireFrameCartProjected[0,1]], [XWireFrameCartProjected[1,0], XWireFrameCartProjected[1,1]],'g-')     \n",
    "        plt.plot([XWireFrameCartProjected[0,1], XWireFrameCartProjected[0,2]], [XWireFrameCartProjected[1,1], XWireFrameCartProjected[1,2]],'g-')     \n",
    "        plt.plot([XWireFrameCartProjected[0,2], XWireFrameCartProjected[0,3]], [XWireFrameCartProjected[1,2], XWireFrameCartProjected[1,3]],'g-')     \n",
    "        plt.plot([XWireFrameCartProjected[0,0],XWireFrameCartProjected[0,3]], [XWireFrameCartProjected[1,0],XWireFrameCartProjected[1,3]],'g-') \n",
    "\n",
    "        # top\n",
    "        plt.plot([XWireFrameCartProjected[0,4],XWireFrameCartProjected[0,5]], [XWireFrameCartProjected[1,4],XWireFrameCartProjected[1,5]],'g-')\n",
    "        plt.plot([XWireFrameCartProjected[0,5],XWireFrameCartProjected[0,6]], [XWireFrameCartProjected[1,5],XWireFrameCartProjected[1,6]],'g-')\n",
    "        plt.plot([XWireFrameCartProjected[0,6],XWireFrameCartProjected[0,7]], [XWireFrameCartProjected[1,6],XWireFrameCartProjected[1,7]],'g-')\n",
    "        plt.plot([XWireFrameCartProjected[0,4],XWireFrameCartProjected[0,7]], [XWireFrameCartProjected[1,4],XWireFrameCartProjected[1,7]],'g-') \n",
    "\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remark:\n",
    "The plots above show the real 2d points (red) and estimated 3D cube points (green). The green lines connect the projected 3D cube points and construct an estimated 3D cube. I notice that the estimated points do not match the real corners perfectly. This might be caused by the error when calculating SVD (used for computing the homography) and tracking the corners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q:\n",
    "Consider this simplistic example, and mention at least two actions or changes we could make to improve the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A:\n",
    "1. We can track four corners at the same time instead of tracking single corner because the corners will have relation with each other. Or we could use more points to track the corners, edges and centres of the 2D square.\n",
    "2. The corner positions will not change very obviously between frames. The previous frame will influence the weight of the points in next frame. We might use more states and consider the relations among previous frames, which might help to increase the accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
